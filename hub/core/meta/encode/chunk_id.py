from hub.constants import ENCODING_DTYPE, UUID_SHIFT_AMOUNT
from hub.util.exceptions import ChunkIdEncoderError
import hub
from hub.core.storage.cachable import Cachable
from io import BytesIO
from typing import Optional, Tuple, Union, List
import numpy as np
from uuid import uuid4
from hub.core.lowlevel import encode_chunkids, decode_chunkids
from hub.core.index import IndexEntry
import math


# these constants are for accessing the data layout. see the `ChunkIdEncoder` docstring.
CHUNK_ID_INDEX = 0
LAST_INDEX_INDEX = 1


class ChunkIdEncoder(Cachable):
    def __init__(self, ids=None):
        """Custom compressor that allows reading of chunk IDs from a sample index without decompressing.

        Chunk IDs:
            Chunk IDs are a `ENCODING_DTYPE` value  and this class handles generating/encoding them.

        Layout:
            `_encoded_ids` is a 2D array.

            Rows:
                The number of rows is equal to the number of chunk IDs this encoder is responsible for.

            Columns:
                The number of columns is 2.
                Each row looks like this: [chunk_id, last_index], where `last_index` is the last index that the
                chunk with `chunk_id` contains.

            Example:
                >>> enc = ChunkIdEncoder()
                >>> enc.generate_chunk_id()
                >>> enc.num_chunks
                1
                >>> enc.register_samples_to_last_chunk_id(10)
                >>> enc.num_samples
                10
                >>> enc.register_samples_to_last_chunk_id(10)
                >>> enc.num_samples
                20
                >>> enc.num_chunks
                1
                >>> enc.generate_chunk_id()
                >>> enc.register_samples_to_last_chunk_id(1)
                >>> enc.num_samples
                21
                >>> enc._encoded_ids
                [[3723322941, 19],
                 [1893450271, 20]]
                >>> enc[20]
                1893450271

            Best case scenario:
                The best case scenario is when all samples fit within a single chunk. This means the number of rows is 1,
                providing a O(1) lookup.

            Worst case scenario:
                The worst case scenario is when only 1 sample fits per chunk. This means the number of rows is equal to the number
                of samples, providing a O(log(N)) lookup.

            Lookup algorithm:
                To get the chunk ID for some sample index, you do a binary search over the right-most column. This will give you
                the row that corresponds to that sample index (since the right-most column is our "last index" for that chunk ID).
                Then, you get the left-most column and that is your chunk ID!

        """
        self._buffer: List[List[int]] = []
        self._data: List[np.ndarray] = [] if ids is None else [ids]
        self._num_chunks = sum(map(len, self._data))

        self._prev_sample_index: Optional[int] = None
        self._prev_chunk_id: Optional[int] = None
        self._prev_chunk_index: Optional[Tuple[int, int]] = None
        self._prev_entry: Optional[Union[np.ndarray, List[int]]] = None

    def _flush_buffer(self):
        if self._buffer:
            self._data.append(np.array(self._buffer, dtype=ENCODING_DTYPE))
        if self._prev_chunk_index and self._prev_chunk_index[0] < 0:
            self._prev_chunk_index = (len(self._data) - 1, self._prev_chunk_index[1])
        self._buffer.clear()

    def _get_2d_idx(self, idx: int) -> Tuple[int, int]:
        i = 0
        data = self._data
        while True:
            try:
                num_data_i = len(data[i])
            except IndexError:  # slightly faster than checking i < len(self._data) in a loop
                return -1, idx
            if num_data_i <= idx:
                idx -= num_data_i
                i += 1
            else:
                break
        return i, idx

    def tobytes(self) -> memoryview:
        self._flush_buffer()
        encoded = encode_chunkids(hub.__version__, self._data)
        decoded = decode_chunkids(encoded)[1]
        if self._data:
            np.testing.assert_array_equal(
                decoded, np.concatenate(self._data), err_msg=str(bytes(encoded))
            )
        return encoded

    @staticmethod
    def name_from_id(id: ENCODING_DTYPE) -> str:
        """Returns the hex of `id` with the "0x" prefix removed. This is the chunk's name and should be used to determine the chunk's key.
        Can convert back into `id` using `id_from_name`. You can get the `id` for a chunk using `__getitem__`."""

        return hex(id)[2:]

    @staticmethod
    def id_from_name(name: str) -> ENCODING_DTYPE:
        """Returns the 64-bit integer from the hex `name` generated by `name_from_id`."""

        return int("0x" + name, 16)

    def get_name_for_chunk(self, chunk_index: int) -> str:
        """Gets the name for the chunk at index `chunk_index`. If you need to get the name for a chunk from a sample index, instead
        use `__getitem__`, then `name_from_id`."""
        chunk_id = self.get_entry(chunk_index)[CHUNK_ID_INDEX]
        return ChunkIdEncoder.name_from_id(chunk_id)

    @classmethod
    def frombuffer(cls, buffer: bytes):
        version, ids = decode_chunkids(buffer)
        return cls(ids)

    @property
    def num_chunks(self) -> int:
        return self._num_chunks

    def get_entry(self, idx: int):
        x, y = self._get_2d_idx(idx)
        return self._buffer[y] if x < 0 else self._data[x][y]

    def _get_entry_2d(self, x: int, y: int):
        return self._buffer[y] if x < 0 else self._data[x][y]

    def _decr_2d(self, x: int, y: int) -> Tuple[int, int]:
        if x < 0:
            if y:
                return x, y - 1
            return len(self._data) - 1, len(self._data[-1]) - 1
        if y:
            return x, y - 1
        if x:
            x -= 1
            return x, len(self._data[x]) - 1
        raise IndexError()

    def _incr_2d(self, x: int, y: int) -> Tuple[int, int]:
        if x < 0:
            return x, y + 1
        # assert y < len(self._data[x])
        if y == len(self._data[x]) - 1:
            if x == len(self._data) - 1:
                return -1, 0
            return x + 1, 0
        return x, y + 1

    def _is_origin(self, x: int, y: int) -> bool:
        if not x and not y:
            return True
        if x < 0 and not self._data and not y:
            return True
        return False

    @property
    def last_entry(self) -> Union[np.ndarray, List[int]]:
        if self._buffer:
            return self._buffer[-1]
        if self._data:
            return self._data[-1][-1]
        return None

    @property
    def last_index(self) -> int:
        last_entry = self.last_entry
        if last_entry is None:
            return -1
        return int(last_entry[LAST_INDEX_INDEX])

    @property
    def num_samples(self) -> int:
        if self._buffer:
            return int(self._buffer[-1][LAST_INDEX_INDEX] + 1)
        elif self._data:
            return int(self._data[-1][-1, LAST_INDEX_INDEX] + 1)
        return 0

    @property
    def empty(self) -> bool:
        return not self._buffer and not self._data

    def generate_chunk_id(self) -> ENCODING_DTYPE:
        """Generates a random 64bit chunk ID using uuid4. Also prepares this ID to have samples registered to it.
        This method should be called once per chunk created.

        Returns:
            ENCODING_DTYPE: The random chunk ID.
        """
        id = ENCODING_DTYPE(uuid4().int >> UUID_SHIFT_AMOUNT)
        self._buffer.append([id, self.last_index])
        self._num_chunks += 1
        return id

    def register_samples_to_last_chunk_id(self, num_samples: int):
        """Registers samples to the chunk ID that was generated last with the `generate_chunk_id` method.
        This method should be called at least once per chunk created.

        Args:
            num_samples (int): The number of samples the last chunk ID should have added to it's registration.

        Raises:
            ValueError: `num_samples` should be non-negative.
            ChunkIdEncoderError: Must call `generate_chunk_id` before registering samples.
            ChunkIdEncoderError: `num_samples` can only be 0 if it is able to be a sample continuation accross chunks.
        """
        if num_samples < 0:
            raise ValueError(
                f"Cannot register negative num samples. Got: {num_samples}"
            )

        if self.empty:
            raise ChunkIdEncoderError(
                f"Cannot register samples because no chunk IDs exist. {self._buffer}, {self._data}"
            )

        if num_samples == 0 and self.num_chunks < 2:
            raise ChunkIdEncoderError(
                "Cannot register 0 num_samples (signifying a partial sample continuing the last chunk) when no last chunk exists."
            )

        last_entry = self.last_entry
        if self._buffer:
            last_entry[LAST_INDEX_INDEX] += num_samples
        else:
            err = np.geterr()["over"]
            np.seterr(over="ignore")
            last_entry[LAST_INDEX_INDEX] += ENCODING_DTYPE(num_samples)
            np.seterr(over=err)

    def get_local_sample_index(self, global_sample_index: int) -> int:
        """Converts `global_sample_index` into a new index that is relative to the chunk the sample belongs to.

        Example:
            Given: 2 sampes in chunk 0, 2 samples in chunk 1, and 3 samples in chunk 2.

            >>> self.num_samples
            7
            >>> self.num_chunks
            3
            >>> self.get_local_sample_index(0)
            0
            >>> self.get_local_sample_index(1)
            1
            >>> self.get_local_sample_index(2)
            0
            >>> self.get_local_sample_index(3)
            1
            >>> self.get_local_sample_index(6)
            2

        Args:
            global_sample_index (int): Index of the sample relative to the containing tensor.

        Returns:
            int: local index value between 0 and the amount of samples the chunk contains - 1.
        """

        return self.get(global_sample_index, return_local_sample_index=True)[1]  # type: ignore

    def __getitem__(self, sample_index: int) -> int:
        return self.get(sample_index)  # type: ignore

    def get(
        self,
        sample_index: int,
        return_chunk_index: bool = False,
        return_local_sample_index: bool = False,
    ) -> Union[
        int,
        Tuple[int, Tuple[int, int]],
        Tuple[int, Tuple[int, int], int],
        Tuple[int, int],
    ]:
        """Get the ID for the chunk that `sample_index` is stored in.
        To get the name of the chunk, use `name_from_id`.

        Args:
            sample_index (int): Global index (relative to the tensor). This will be converted to the local chunk index.
            return_chunk_index (bool): If True, 2 values are returned, the second one being the chunk's index. Defaults to False.

        Raises:
            IndexError: If no samples exist or `sample_index` exceeds the available indices.

        Returns:
            Tuple[Tuple[ENCODING_DTYPE], Optional[Tuple[int]]]: Returns the chunk ID for `sample_index`. If `return_chunk_index` is True,
                there will be 2 values. The second one being the chunk's index.
        """
        if self.num_samples == 0:
            raise IndexError(
                f"Index {sample_index} is out of bounds for an empty chunk names encoding."
            )

        if sample_index < 0:
            sample_index = (self.num_samples) + sample_index

        chunk_id = None
        if (
            self._prev_sample_index is not None
            and sample_index >= self._prev_sample_index
        ):
            if sample_index <= self._prev_entry[LAST_INDEX_INDEX]:
                chunk_id = self._prev_chunk_id
                chunk_index = self._prev_chunk_index
                current_entry = self._prev_entry
            else:
                next_index = self._incr_2d(*self._prev_chunk_index)  # type: ignore
                next_entry = self._get_entry_2d(*next_index)
                if sample_index <= next_entry[LAST_INDEX_INDEX]:
                    chunk_index = next_index
                    current_entry = next_entry
                    chunk_id = current_entry[CHUNK_ID_INDEX]

        if chunk_id is None:
            self._flush_buffer()
            last_idxs = [shard[-1, LAST_INDEX_INDEX] for shard in self._data]
            shard_index = np.searchsorted(last_idxs, sample_index)
            shard = self._data[shard_index]
            idx = np.searchsorted(shard[:, LAST_INDEX_INDEX], sample_index)
            current_entry = shard[idx]
            chunk_id = current_entry[CHUNK_ID_INDEX]
            chunk_index = (shard_index, idx)

        self._prev_sample_index = sample_index
        self._prev_chunk_index = chunk_index
        self._prev_entry = current_entry
        self._prev_chunk_id = chunk_id

        if not return_chunk_index and not return_local_sample_index:
            return chunk_id
        ret = [chunk_id]
        if return_chunk_index:
            ret.append(chunk_index)
        if return_local_sample_index:
            if any(chunk_index):
                prev_entry = self._get_entry_2d(*self._decr_2d(*chunk_index))
                local_sample_index = (
                    sample_index - int(prev_entry[LAST_INDEX_INDEX]) - 1
                )
            else:
                local_sample_index = sample_index
            ret.append(local_sample_index)

        return tuple(ret)  # type: ignore

    def iter(self, index: Union[int, slice, tuple] = slice(None)):
        if isinstance(index, int):
            yield self.get(index, return_local_sample_index=True)
        elif isinstance(index, slice):
            start = 0 if index.start is None else index.start
            stop = self.num_samples if index.stop is None else index.stop
            step = 1 if index.step is None else index.step
            assert isinstance(start, int)
            assert isinstance(stop, int)
            assert isinstance(step, int)
            assert step != 0
            if step > 0:
                total = math.ceil((stop - start) / step)
                forward = True
            else:
                step = -step
                total = math.ceil((stop - start) / step)
                start, stop = stop - 1, start
                forward = False
            if not total:
                return
            n = 0
            self._flush_buffer()
            chunk_id, (shard_index, chunk_index), local_sample_index = self.get(  # type: ignore
                start, return_chunk_index=True, return_local_sample_index=True
            )
            shard = self._data[shard_index]
            yield chunk_id, local_sample_index
            n += 1
            if n == total:
                return
            ctr = Counter(step)
            if forward:
                last_index = int(shard[chunk_index, LAST_INDEX_INDEX])
                for i in range(local_sample_index + 1, last_index + 1):
                    if ctr():
                        yield chunk_id, i
                        n += 1
                        if n == total:
                            return
                for chunk_index in range(chunk_index + 1, len(shard)):
                    entry = shard[chunk_index]
                    chunk_id = entry[CHUNK_ID_INDEX]
                    new_last_index = int(entry[LAST_INDEX_INDEX])
                    for i in range(new_last_index - last_index):
                        if ctr():
                            yield chunk_id, i
                            n += 1
                            if n == total:
                                return
                    last_index = new_last_index
                for shard_index in range(shard_index + 1, len(self._data)):
                    shard = self._data[shard_index]
                    for entry in shard:
                        chunk_id = entry[CHUNK_ID_INDEX]
                        new_last_index = int(entry[LAST_INDEX_INDEX])
                        for i in range(new_last_index - last_index):
                            if ctr():
                                yield chunk_id, i
                                n += 1
                                if n == total:
                                    return
                        last_index = new_last_index
            else:
                last_index = int(shard[chunk_index, LAST_INDEX_INDEX])
                for local_sample_index in range(local_sample_index - 1, -1, -1):
                    if ctr():
                        yield chunk_id, local_sample_index
                        n += 1
                        if n == total:
                            return
                for chunk_index in range(chunk_index - 1, -1, -1):
                    entry = shard[chunk_index]
                    chunk_id = entry[CHUNK_ID_INDEX]
                    last_index = entry[LAST_INDEX_INDEX]
                    if chunk_index:
                        last_index -= shard[chunk_id - 1, LAST_INDEX_INDEX]
                    elif shard_index:
                        last_index -= self._data[shard_index - 1][-1, LAST_INDEX_INDEX]
                    for local_sample_index in range(last_index, -1, -1):
                        if ctr():
                            yield chunk_id, local_sample_index
                            n += 1
                            if n == total:
                                return
                for shard_index in range(shard_index - 1, -1, -1):
                    shard = self._data[shard_index]
                    for chunk_index in range(len(shard) - 1, -1, -1):
                        entry = shard[chunk_index]
                        chunk_id = entry[CHUNK_ID_INDEX]
                        last_index = entry[LAST_INDEX_INDEX]
                        if chunk_index:
                            last_index -= shard[chunk_id - 1, LAST_INDEX_INDEX]
                        elif shard_index:
                            last_index -= self._data[shard_index - 1][
                                -1, LAST_INDEX_INDEX
                            ]
                        for local_sample_index in range(last_index, -1, -1):
                            if ctr():
                                yield chunk_id, local_sample_index
                                n += 1
                                if n == total:
                                    return
        elif isinstance(index, tuple):
            for i in index:
                # Random access
                yield self.get(i, return_local_sample_index=True)


class Counter:
    # TODO: refac this
    def __init__(self, n: int) -> None:
        self.n = n
        self.i = 0

    def __call__(self):
        self.i += 1
        if self.i == self.n:
            self.i = 0
            return True
        return False
